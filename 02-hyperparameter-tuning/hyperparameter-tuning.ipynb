{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização de hiperparâmetros\n",
    "\n",
    "* Nada mais é do que um **problema de otimização**, onde você busca encontrar um **mínimo ou um máximo** para uma função\n",
    "* No contexto de Machine Learning, a ideia é encontrar a **melhor configuração de hiperparâmetros** de modo a maximimizar o **desempenho** do seu modelo\n",
    "\n",
    "## O que vamos ver hoje\n",
    "\n",
    "1. Primeiro iremos entender o **funcionamento** dos otimizadores com uma **função simples**\n",
    "2. Depois iremos ver uma aplicação **prática em um modelo**\n",
    "3. Iremos ver também uma maneira de **lidar com overfitting** através dos hiperparâmetros\n",
    "4. Por último iremos ver **funcionalidades avançadas** que facilitam muito o dia-a-dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Usando o otimizadores para achar o mínimo de uma função matemática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função matemática com mínimo em: x = 8.33 e y = -6.47 e o valor mínimo é -26.07\n",
    "def function(x, y):\n",
    "    return (x - 5.1) ** 2 + (y + 2.3) ** 2 + x * y\n",
    "\n",
    "utils.plot_function(function);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_options = np.arange(-10, 12, 2)\n",
    "y_options = np.arange(-10, 12, 2)\n",
    "grid = np.meshgrid(x_options, y_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = utils.plot_function(function)\n",
    "ax.scatter(grid[0], grid[1], marker=\"x\", color=\"black\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(function(grid[0], grid[1]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin = np.argmin(function(grid[0], grid[1]).flatten())\n",
    "grid[0].flatten()[argmin], grid[1].flatten()[argmin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    y = trial.suggest_float(\"y\", -10, 10)\n",
    "    return function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = utils.plot_function(function)\n",
    "ax.scatter(study.trials_dataframe()[\"params_x\"], study.trials_dataframe()[\"params_y\"], marker=\"x\", color=\"black\")\n",
    "ax.scatter(**study.best_params, marker=\"x\", color=\"y\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params, study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Otimizando um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/UCI_Credit_Card.csv\", index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val, df_test = train_test_split(df, test_size=0.2, random_state=23)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.2, random_state=23)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"default.payment.next.month\"\n",
    "features = [col for col in df_train.columns if col != target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando um modelo sem tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(verbose=-1)\n",
    "model.fit(df_train[features], df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"pred\"] = model.predict_proba(df_train[features])[:, 1]\n",
    "df_test[\"pred\"] = model.predict_proba(df_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_train[target], df_train[\"pred\"]), roc_auc_score(df_test[target], df_test[\"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"random_state\": 23,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.00001, 10, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 32, 256),\n",
    "    }\n",
    "    model = LGBMClassifier(**params, verbose=-1)\n",
    "    model.fit(df_train[features], df_train[target])\n",
    "    pred = model.predict_proba(df_val[features])[:, 1]\n",
    "\n",
    "    return roc_auc_score(df_val[target], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(**study.best_params, verbose=-1)\n",
    "model.fit(df_train[features], df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"pred\"] = model.predict_proba(df_train[features])[:, 1]\n",
    "df_test[\"pred\"] = model.predict_proba(df_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_train[target], df_train[\"pred\"]), roc_auc_score(df_test[target], df_test[\"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Reduzindo overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um métrica personalizada para reduzir overfitting\n",
    "$$metric = {1 \\over 1 + abs(AUC_V - AUC_T)} * AUC_V$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"random_state\": 23,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.00001, 10, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 32, 256),\n",
    "    }\n",
    "    model = LGBMClassifier(**params, verbose=-1)\n",
    "    model.fit(df_train[features], df_train[target])\n",
    "    pred = model.predict_proba(df_val[features])[:, 1]\n",
    "    pred_train = model.predict_proba(df_train[features])[:, 1]\n",
    "\n",
    "    auc_val = roc_auc_score(df_val[target], pred)\n",
    "    auc_train = roc_auc_score(df_train[target], pred_train)\n",
    "    \n",
    "    return (1 / (1 + abs(auc_val - auc_train))) * auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(**study.best_params, verbose=-1)\n",
    "model.fit(df_train[features], df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"pred\"] = model.predict_proba(df_train[features])[:, 1]\n",
    "df_test[\"pred\"] = model.predict_proba(df_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_train[target], df_train[\"pred\"]), roc_auc_score(df_test[target], df_test[\"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra 2: Tópicos avançados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", storage=\"sqlite:///optuna.db\", pruner=optuna.pruners.HyperbandPruner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"random_state\": 23,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.00001, 10, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 32, 256),\n",
    "    }\n",
    "\n",
    "    auc_val = []\n",
    "    for idx, (train_idx, val_idx) in enumerate(KFold(n_splits=3).split(df_train_val)):\n",
    "        model = LGBMClassifier(**params, verbose=-1)\n",
    "        model.fit(df_train_val.iloc[train_idx][features], df_train_val.iloc[train_idx][target])\n",
    "        pred = model.predict_proba(df_train_val.iloc[val_idx][features])[:, 1]\n",
    "\n",
    "        auc_val.append(roc_auc_score(df_train_val.iloc[val_idx][target], pred))\n",
    "\n",
    "        trial.report(auc_val[-1], idx)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return np.mean(auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
